{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "Due by 10/12/15 at 11:59pm EST\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Regression (20 pts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a \n",
    "\n",
    "Compare different models for the regressionP1.txt file where you are to model output given combinations of the x1, x2, and x3 variables and find the best model.  Note that you can include not only the individual variables but the 2- and 3-way interactions that use the format x1:x2 or x1:x2:x3.  How did you determine the best model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "Using the best model from 1a), analyze the regression assumptions.  This should include at least a histogram of the residuals, residuals as a function of the output, and a q-q plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2  Hierarchical Clustering (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of data has the following distance matrix.  Use the distance matrix approach to cluster this data by hand or using python calculations.  Produce the following output of the form for a hierarchical clustering using the Centroid based clustering. \n",
    "\n",
    "HigherCol     LowerCol     distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src='distmtx.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3  Gradient Search (15 pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3a  \n",
    "\n",
    "Use a gradient search approach to find the minimum value of:\n",
    "\n",
    "f(x,y,z) = (z-3x)4 exp(x-y) + (3x + y + 2z + 7)2exp(y-z)\n",
    "\n",
    "The gradient of the function is [dx dy dz] defined below. \n",
    "\n",
    "dx:\t -12(z-3x)3 exp(x-y) + (z-3x)4 exp(x-y) + 6(3x + y + 2z + 7)exp(y-z)\n",
    "\n",
    "dy:\t(z-3x) 4 exp(x-y)(-1) + 2(3x + y + 2z + 7)exp(y-z) + (3x+y+2z+7)2exp(y-z)\n",
    "\n",
    "dz:\t4(z-3x)3 exp(x-y) + 4(3x + y + 2z + 7)exp(y-z) - (3x + y + 2z + 7)2exp(y-z)\n",
    "\n",
    "Start at least with [x=-1 y=0 z=1] and explore different learning rates (alpha).  How sensitive is the gradient to the initial starting point?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3b\n",
    "\n",
    "An extremely common error in gradient searches is that either the gradient equation or the implementation are wrong.  A quick check is to look at the neighborhood of a given start point.  For the starting point, verify that a point f(x+deltax, y+deltay, z+deltaz) is lower than f(x,y,z) where the  deltax, deltay, and deltaz are small numbers in the appropriate direction of the calculated gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4  K-Modes (35 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4a  \n",
    "Write a k-modes algorithm.  We suggest that you find a k-means algorithm available pretty much everywhere and adapt it to perform k-modes for categorical data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4b  \n",
    "Cluster the attached sponge data using your k-modes algorithm.  Recall that the mode is the most frequently occurring pattern in categorical data.  Note that the first column of this data set is a set of labels, not data points.  To show the results, print a list of the output column labels on separate lines.  That is if you find 3 clusters (a,b,c), (d), (e,f), the output should look like\n",
    "\n",
    "a b c<br/>\n",
    "d<br/>\n",
    "e f<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4c\n",
    "Justify your choice of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 Gaussian Mixture Model (15 pts)\n",
    "\n",
    "Clustering using K-Means and Gaussian Mixture Models.  Cluster the gmmDataP5.txt file using 4 clusters for each.  You may need to try multiple different starting locations to get a stable result.   We recommend using the the scikit-learn k-Means and mixture GMM for this, although the PyMix from section would be equivalent and acceptable (but needs the older Python 2.7).   How do the results of the clustering compare?    Print the mean and covariances for the GMM, and the centroids for the k-means.\n",
    "Plotting the raw data points and ellipses for the GMM is useful but optional, but worth a few bonus points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 Bonus question:\n",
    "Write your own implementation of EM algorithm applied to the Gaussian Mixture Models.  Apply it to the same data set.  You do not have to generalize it to N dimensionsâ€”2 dimensions is sufficient for this problem if that is easier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "Due by 10/12/15 at 11:59pm EST\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "## Start working 10/1/2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Regression (20 pts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1a \n",
    "\n",
    "Compare different models for the regressionP1.txt file where you are to model output given combinations of the x1, x2, and x3 variables and find the best model.  Note that you can include not only the individual variables but the 2- and 3-way interactions that use the format x1:x2 or x1:x2:x3.  How did you determine the best model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        output         x1         x2        x3\n",
      "0    71.563815  66.225189  66.034689  0.237877\n",
      "1    68.095027  64.865348  62.602534  0.146580\n",
      "2    70.010759  64.452389  65.625861  0.131727\n",
      "3    76.487794  69.237457  66.253043  0.317875\n",
      "4    70.199166  66.703416  63.492743  0.368067\n",
      "5    68.269832  63.473138  61.646649 -0.265088\n",
      "6    69.809785  68.517855  64.495314  0.795495\n",
      "7    66.791850  65.985788  62.872631 -0.426988\n",
      "8    73.661319  64.290291  70.547968  0.207851\n",
      "9    75.977383  65.904010  70.644204 -0.282136\n",
      "10   70.496917  66.387802  63.982758 -0.139556\n",
      "11   69.876383  68.329408  68.258907  0.110387\n",
      "12   77.939047  66.121277  60.436617  0.056269\n",
      "13   65.124782  60.033373  61.251145 -0.019909\n",
      "14   62.905860  60.657624  59.562272 -0.626566\n",
      "15   63.756901  60.855059  62.475514 -0.717725\n",
      "16   72.317532  64.463946  60.566484 -0.331824\n",
      "17   74.411329  70.591906  62.578534  0.246055\n",
      "18   70.771139  64.658608  61.839738 -0.482220\n",
      "19   70.476725  63.990048  61.670896 -0.358460\n",
      "20   67.803271  61.572658  60.770118 -0.809698\n",
      "21   68.028811  69.361607  65.308656  0.810482\n",
      "22   65.430721  63.176832  64.245628  0.453672\n",
      "23   66.685022  66.441740  66.834183  0.069640\n",
      "24   70.901191  65.331887  64.829128  0.348597\n",
      "25   68.278028  64.452390  62.796924 -0.494243\n",
      "26   73.822209  66.473471  64.518400  0.247409\n",
      "27   67.120320  65.383144  61.200419  0.486682\n",
      "28   67.391194  63.147029  60.896760 -0.343798\n",
      "29   74.394442  63.799817  64.627126 -0.054432\n",
      "..         ...        ...        ...       ...\n",
      "184  67.007668  65.308691  62.476617 -0.481874\n",
      "185  72.192363  63.660775  60.084152  0.035019\n",
      "186  74.353852  68.717675  66.964321  0.812417\n",
      "187  71.171248  68.669429  62.517301  0.121717\n",
      "188  71.588557  65.835888  63.549125 -0.010323\n",
      "189  68.495178  63.458539  65.177867 -0.132269\n",
      "190  67.836397  62.407448  60.141581 -0.942577\n",
      "191  68.338251  63.502971  66.414493  0.268514\n",
      "192  72.623073  71.947773  69.398762  0.482190\n",
      "193  68.370989  63.137832  63.288065 -0.473398\n",
      "194  66.436923  63.323786  63.329159 -0.079483\n",
      "195  66.546080  62.434361  64.177904 -0.710290\n",
      "196  67.864406  63.786121  61.355105 -0.231035\n",
      "197  68.611924  65.898144  67.636295 -0.489251\n",
      "198  73.929436  65.613387  64.820568  0.369838\n",
      "199  72.623256  64.446139  58.987594 -0.379784\n",
      "200  72.179968  68.371423  68.393194  0.860770\n",
      "201  68.634396  64.941296  63.278123  0.336256\n",
      "202  67.326703  61.910711  62.003676 -0.468612\n",
      "203  66.073969  62.376065  60.939899 -0.363743\n",
      "204  71.044308  66.577886  62.653006  0.485408\n",
      "205  72.031585  68.707876  66.935533  0.491822\n",
      "206  68.501726  65.864106  64.505836  0.136522\n",
      "207  75.902700  69.465425  65.390078  0.869886\n",
      "208  72.690842  65.159434  69.238990 -0.352515\n",
      "209  72.002024  64.789960  68.752610  0.198947\n",
      "210  70.414486  64.505738  64.636375  0.464337\n",
      "211  71.109287  67.070663  62.071912  0.944513\n",
      "212  67.319798  68.857180  65.939161  0.783832\n",
      "213  76.166044  73.952581  68.361516  0.022685\n",
      "\n",
      "[214 rows x 4 columns] 0      71.563815\n",
      "1      68.095027\n",
      "2      70.010759\n",
      "3      76.487794\n",
      "4      70.199166\n",
      "5      68.269832\n",
      "6      69.809785\n",
      "7      66.791850\n",
      "8      73.661319\n",
      "9      75.977383\n",
      "10     70.496917\n",
      "11     69.876383\n",
      "12     77.939047\n",
      "13     65.124782\n",
      "14     62.905860\n",
      "15     63.756901\n",
      "16     72.317532\n",
      "17     74.411329\n",
      "18     70.771139\n",
      "19     70.476725\n",
      "20     67.803271\n",
      "21     68.028811\n",
      "22     65.430721\n",
      "23     66.685022\n",
      "24     70.901191\n",
      "25     68.278028\n",
      "26     73.822209\n",
      "27     67.120320\n",
      "28     67.391194\n",
      "29     74.394442\n",
      "         ...    \n",
      "184    67.007668\n",
      "185    72.192363\n",
      "186    74.353852\n",
      "187    71.171248\n",
      "188    71.588557\n",
      "189    68.495178\n",
      "190    67.836397\n",
      "191    68.338251\n",
      "192    72.623073\n",
      "193    68.370989\n",
      "194    66.436923\n",
      "195    66.546080\n",
      "196    67.864406\n",
      "197    68.611924\n",
      "198    73.929436\n",
      "199    72.623256\n",
      "200    72.179968\n",
      "201    68.634396\n",
      "202    67.326703\n",
      "203    66.073969\n",
      "204    71.044308\n",
      "205    72.031585\n",
      "206    68.501726\n",
      "207    75.902700\n",
      "208    72.690842\n",
      "209    72.002024\n",
      "210    70.414486\n",
      "211    71.109287\n",
      "212    67.319798\n",
      "213    76.166044\n",
      "Name: output, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Read text file into variable data\n",
    "data = pd.read_csv('regressionP1.txt', sep='')\n",
    "# Extract the output column data into var y\n",
    "y = data['output']\n",
    "print(data,y)\n",
    "\n",
    "# ## scatter matrix\n",
    "# pd.scatter_matrix(d1, alpha=0.2, figsize=(14,14), diagonal='kde')\n",
    "\n",
    "# ## add interaction terms\n",
    "# d1['x1*x2'] = d1['x1'] * d1['x2']\n",
    "# d1['x1*x3'] = d1['x1'] * d1['x3']\n",
    "# d1['x2*x3'] = d1['x2'] * d1['x3']\n",
    "\n",
    "# ## model 1: all x\n",
    "# x = d1[['x1', 'x2', 'x3']]\n",
    "# model = sm.OLS(y, x)\n",
    "# result = model.fit()\n",
    "# print(result.summary())\n",
    "\n",
    "# ## model 2: all x and interactions\n",
    "# x = d1[['x1', 'x2', 'x3', 'x1*x2', 'x1*x3', 'x2*x3']]\n",
    "# model = sm.OLS(y, x)\n",
    "# result = model.fit()\n",
    "# print(result.summary())\n",
    "\n",
    "\n",
    "## RESULT:\n",
    "## In both models, there are x1, x2, and x1*x2 that have significant coefficients. We can leave out x3\n",
    "## In the next step, we should try to compare model x1, x2, vs. x1, x2, x1*x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "Using the best model from 1a), analyze the regression assumptions.  This should include at least a histogram of the residuals, residuals as a function of the output, and a q-q plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2  Hierarchical Clustering (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of data has the following distance matrix.  Use the distance matrix approach to cluster this data by hand or using python calculations.  Produce the following output of the form for a hierarchical clustering using the Centroid based clustering. \n",
    "\n",
    "HigherCol     LowerCol     distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src='distmtx.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3  Gradient Search (15 pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3a  \n",
    "\n",
    "Use a gradient search approach to find the minimum value of:\n",
    "\n",
    "f(x,y,z) = (z-3x)4 exp(x-y) + (3x + y + 2z + 7)2exp(y-z)\n",
    "\n",
    "The gradient of the function is [dx dy dz] defined below. \n",
    "\n",
    "dx:\t -12(z-3x)3 exp(x-y) + (z-3x)4 exp(x-y) + 6(3x + y + 2z + 7)exp(y-z)\n",
    "\n",
    "dy:\t(z-3x) 4 exp(x-y)(-1) + 2(3x + y + 2z + 7)exp(y-z) + (3x+y+2z+7)2exp(y-z)\n",
    "\n",
    "dz:\t4(z-3x)3 exp(x-y) + 4(3x + y + 2z + 7)exp(y-z) - (3x + y + 2z + 7)2exp(y-z)\n",
    "\n",
    "Start at least with [x=-1 y=0 z=1] and explore different learning rates (alpha).  How sensitive is the gradient to the initial starting point?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3b\n",
    "\n",
    "An extremely common error in gradient searches is that either the gradient equation or the implementation are wrong.  A quick check is to look at the neighborhood of a given start point.  For the starting point, verify that a point f(x+deltax, y+deltay, z+deltaz) is lower than f(x,y,z) where the  deltax, deltay, and deltaz are small numbers in the appropriate direction of the calculated gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4  K-Modes (35 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4a  \n",
    "Write a k-modes algorithm.  We suggest that you find a k-means algorithm available pretty much everywhere and adapt it to perform k-modes for categorical data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4b  \n",
    "Cluster the attached sponge data using your k-modes algorithm.  Recall that the mode is the most frequently occurring pattern in categorical data.  Note that the first column of this data set is a set of labels, not data points.  To show the results, print a list of the output column labels on separate lines.  That is if you find 3 clusters (a,b,c), (d), (e,f), the output should look like\n",
    "\n",
    "a b c<br/>\n",
    "d<br/>\n",
    "e f<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4c\n",
    "Justify your choice of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 Gaussian Mixture Model (15 pts)\n",
    "\n",
    "Clustering using K-Means and Gaussian Mixture Models.  Cluster the gmmDataP5.txt file using 4 clusters for each.  You may need to try multiple different starting locations to get a stable result.   We recommend using the the scikit-learn k-Means and mixture GMM for this, although the PyMix from section would be equivalent and acceptable (but needs the older Python 2.7).   How do the results of the clustering compare?    Print the mean and covariances for the GMM, and the centroids for the k-means.\n",
    "Plotting the raw data points and ellipses for the GMM is useful but optional, but worth a few bonus points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 Bonus question:\n",
    "Write your own implementation of EM algorithm applied to the Gaussian Mixture Models.  Apply it to the same data set.  You do not have to generalize it to N dimensionsâ€”2 dimensions is sufficient for this problem if that is easier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

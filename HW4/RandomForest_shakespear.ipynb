{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random forest classifying based on two training models\n",
    "## One uses vectorized 5000 features, one uses Readability features\n",
    "## vectorized 5000 features has a much better performance with homogeneity around 80%\n",
    "\n",
    "%matplotlib inline \n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# #import vectorized feature arrays for acts and scenes\n",
    "act_Vect = pd.read_csv('VectorizedFeatures/AllComplied/AllAct_Features_Vectorize.txt',sep=',',header = None)\n",
    "scene_Vect = pd.read_csv('VectorizedFeatures/AllComplied/AllScene_Features_Vectorize.txt',sep=',',header = None)\n",
    "play_Vect = pd.read_csv('VectorizedFeatures/AllComplied/ALLPlay_Features_Vectorize.txt',sep=',',header = None)\n",
    "\n",
    "#import LSA reduced vectorized feature arrays for acts and scenes\n",
    "act_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Act_Features_Vectorize_LSA.txt',sep=',',header = None)\n",
    "scene_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Scene_Features_Vectorize_LSA.txt',sep=',',header = None )\n",
    "play_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Play_Features_Vectorize_LSA.txt',sep=',',header = None )\n",
    "\n",
    "#import readability features\n",
    "act_Readable = pd.read_csv('Readability_Features/Act_Readability_Feature.txt',sep=',',header = None)\n",
    "scene_Readable = pd.read_csv('Readability_Features/Scene_Readability_Feature.txt',sep=',',header = None )\n",
    "play_Readable = pd.read_csv('Readability_Features/Play_Readability_Feature.txt',sep=',',header = None )\n",
    "\n",
    "#import labels\n",
    "act_Labels = pd.read_csv('LSA_VectorizedFeatures/act_feature_labels.txt',sep='\\n',header = None)\n",
    "scene_Labels= pd.read_csv('LSA_VectorizedFeatures/scene_feature_labels.txt',sep='\\n',header = None )\n",
    "play_Labels= pd.read_csv('LSA_VectorizedFeatures/play_feature_labels.txt',sep='\\n',header = None )\n",
    "\n",
    "# print(scene_Labels)\n",
    "act_genre = pd.read_csv('RandomForests/act_genre.txt',sep='\\n',header = None)\n",
    "scene_genre= pd.read_csv('RandomForests/scene_genre.txt',sep='\\n',header = None )\n",
    "play_genre= pd.read_csv('RandomForests/play_genre.txt',sep='\\n',header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Remove brackets for those genre\n",
    "act_genre = act_genre[0].map(lambda x: x.strip('[').strip(']'))\n",
    "play_genre = play_genre[0].map(lambda x: x.strip('[').strip(']'))\n",
    "scene_genre = scene_genre[0].map(lambda x: x.strip('[').strip(']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split the training and testing data sets, as well as genre labels\n",
    "vect_train, vect_test, readable_train, readable_test, genre_train, genre_test = train_test_split(scene_Vect,scene_Readable, scene_genre,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest using scene vectorized data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest using scene vectorized data...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest_vect = forest.fit(vect_train, genre_train)\n",
    "results_vect = forest.predict(vect_test)\n",
    "# print(results)\n",
    "# print(\"the actual labels are\\n\")\n",
    "# print(genre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted results using vectorized features trainig model are\n",
      "\n",
      "[3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 3.0]\n",
      "the actual results are \n",
      "\n",
      "[3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0]\n",
      "Analysis of prediction results using vectorized features trainig model are\n",
      "\n",
      "Homogeneity: 0.802\n",
      "Completeness: 0.790\n",
      "V-measure: 0.796\n",
      "Adjusted Rand-Index: 0.821\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# results = results.map(lambda x: x.strip('[').strip(']'))\n",
    "predict_results_vect = []\n",
    "for j in range(len(results_vect)):\n",
    "    predict_results_vect.insert(-1,float(results_vect[j].strip('[').strip(']')))\n",
    "\n",
    "\n",
    "## Convert actual results to float array for homogeneity comparison\n",
    "# r = genre_test[0].map(lambda x: x.strip('[').strip(']'))\n",
    "r = genre_test\n",
    "r = np.array(r)\n",
    "actual_results = []\n",
    "for i in range(len(r)):\n",
    "    actual_results.insert(-1,float(r[i]))\n",
    "\n",
    "print(\"the predicted results using vectorized features trainig model are\\n\")\n",
    "print(predict_results_vect)\n",
    "print(\"the actual results are \\n\")\n",
    "print(actual_results)\n",
    "# b = [1,2,4,4]\n",
    "print(\"Analysis of prediction results using vectorized features trainig model are\\n\")\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(predict_results_vect, actual_results))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(predict_results_vect, actual_results))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(predict_results_vect, actual_results))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(predict_results_vect, actual_results))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(scene_Vect, predict_results, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest using scene readability feature data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest using scene readability feature data...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest_read = forest.fit(readable_train, genre_train)\n",
    "results_read = forest.predict(readable_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted results using vectorized features trainig model are\n",
      "\n",
      "[3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0]\n",
      "the actual results are \n",
      "\n",
      "[3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0]\n",
      "Analysis of prediction results using vectorized features trainig model are\n",
      "\n",
      "Homogeneity: 0.181\n",
      "Completeness: 0.181\n",
      "V-measure: 0.181\n",
      "Adjusted Rand-Index: 0.175\n"
     ]
    }
   ],
   "source": [
    "# results = results.map(lambda x: x.strip('[').strip(']'))\n",
    "predict_results_read = []\n",
    "for j in range(len(results_read)):\n",
    "    predict_results_read.insert(-1,float(results_read[j].strip('[').strip(']')))\n",
    "\n",
    "\n",
    "## Convert actual results to float array for homogeneity comparison\n",
    "# r = genre_test[0].map(lambda x: x.strip('[').strip(']'))\n",
    "# r = np.array(r)\n",
    "# actual_results = []\n",
    "# for i in range(len(r)):\n",
    "#     actual_results.insert(-1,float(r[i]))\n",
    "\n",
    "print(\"the predicted results using vectorized features trainig model are\\n\")\n",
    "print(predict_results_read)\n",
    "print(\"the actual results are \\n\")\n",
    "print(actual_results)\n",
    "print(\"Analysis of prediction results using vectorized features trainig model are\\n\")\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(predict_results_read, actual_results))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(predict_results_read, actual_results))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(predict_results_read, actual_results))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(predict_results_read, actual_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

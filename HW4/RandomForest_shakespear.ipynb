{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random forest classifying based on two training models\n",
    "## One uses vectorized 5000 features, one uses Readability features\n",
    "## vectorized 5000 features has a much better performance with homogeneity around 80%\n",
    "\n",
    "%matplotlib inline \n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# #import vectorized feature arrays for acts and scenes\n",
    "act_Vect = pd.read_csv('VectorizedFeatures/AllComplied/AllAct_Features_Vectorize.txt',sep=',',header = None)\n",
    "scene_Vect = pd.read_csv('VectorizedFeatures/AllComplied/AllScene_Features_Vectorize.txt',sep=',',header = None)\n",
    "play_Vect = pd.read_csv('VectorizedFeatures/AllComplied/ALLPlay_Features_Vectorize.txt',sep=',',header = None)\n",
    "\n",
    "#import LSA reduced vectorized feature arrays for acts and scenes\n",
    "act_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Act_Features_Vectorize_LSA.txt',sep=',',header = None)\n",
    "scene_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Scene_Features_Vectorize_LSA.txt',sep=',',header = None )\n",
    "play_Vect_LSA = pd.read_csv('LSA_VectorizedFeatures/Play_Features_Vectorize_LSA.txt',sep=',',header = None )\n",
    "\n",
    "#import readability features\n",
    "act_Readable = pd.read_csv('Readability_Features/Act_Readability_Feature.txt',sep=',',header = None)\n",
    "scene_Readable = pd.read_csv('Readability_Features/Scene_Readability_Feature.txt',sep=',',header = None )\n",
    "play_Readable = pd.read_csv('Readability_Features/Play_Readability_Feature.txt',sep=',',header = None )\n",
    "\n",
    "#import labels\n",
    "act_Labels = pd.read_csv('LSA_VectorizedFeatures/act_feature_labels.txt',sep='\\n',header = None)\n",
    "scene_Labels= pd.read_csv('LSA_VectorizedFeatures/scene_feature_labels.txt',sep='\\n',header = None )\n",
    "play_Labels= pd.read_csv('LSA_VectorizedFeatures/play_feature_labels.txt',sep='\\n',header = None )\n",
    "\n",
    "# print(scene_Labels)\n",
    "act_genre = pd.read_csv('RandomForests/act_genre.txt',sep='\\n',header = None)\n",
    "scene_genre= pd.read_csv('RandomForests/scene_genre.txt',sep='\\n',header = None )\n",
    "play_genre= pd.read_csv('RandomForests/play_genre.txt',sep='\\n',header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Remove brackets for those genre\n",
    "act_genre = act_genre[0].map(lambda x: x.strip('[').strip(']'))\n",
    "play_genre = play_genre[0].map(lambda x: x.strip('[').strip(']'))\n",
    "scene_genre = scene_genre[0].map(lambda x: x.strip('[').strip(']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The euclidean distance  of each play are :\n",
      "\n",
      "{0: 1.0, 1: 0.9999999999999996, 2: 0.9999999999999994, 3: 1.0000000000000002, 4: 1.0, 5: 1.0000000000000004, 6: 1.0, 7: 0.9999999999999997, 8: 1.0000000000000004, 9: 0.9999999999999999, 10: 0.9999999999999999, 11: 0.999999999999999, 12: 1.0000000000000002, 13: 0.9999999999999991, 14: 0.999999999999999, 15: 1.0000000000000002, 16: 0.9999999999999998, 17: 1.0000000000000007, 18: 1.000000000000001, 19: 1.0000000000000004, 20: 1.0, 21: 0.9999999999999996, 22: 1.0000000000000004, 23: 0.9999999999999997, 24: 1.0000000000000007, 25: 1.0, 26: 0.9999999999999999, 27: 0.9999999999999994, 28: 1.0, 29: 0.9999999999999993, 30: 0.9999999999999998, 31: 0.9999999999999998, 32: 1.0000000000000013, 33: 1.0, 34: 1.0, 35: 1.0000000000000004, 36: 1.0000000000000007, 37: 1.0000000000000004, 38: 0.9999999999999998, 39: 0.9999999999999998, 40: 1.0000000000000002, 41: 1.0, 42: 0.9999999999999996, 43: 0.999999999999999, 44: 1.0000000000000004, 45: 0.9999999999999993, 46: 1.0000000000000002, 47: 0.9999999999999997, 48: 1.0000000000000004, 49: 1.0000000000000002, 50: 0.9999999999999996, 51: 1.0000000000000002, 52: 1.0000000000000002, 53: 0.9999999999999998, 54: 0.9999999999999999, 55: 1.0000000000000004, 56: 0.9999999999999994, 57: 0.9999999999999993, 58: 0.9999999999999994, 59: 0.9999999999999993, 60: 1.0000000000000009, 61: 1.000000000000001, 62: 0.9999999999999996, 63: 0.9999999999999993, 64: 1.0000000000000009, 65: 0.9999999999999988, 66: 1.0000000000000002, 67: 1.0, 68: 1.0000000000000009, 69: 0.9999999999999999, 70: 1.0, 71: 0.9999999999999999, 72: 0.9999999999999997, 73: 1.0000000000000002, 74: 1.000000000000001, 75: 1.0000000000000013, 76: 1.0000000000000004, 77: 1.0000000000000002, 78: 1.0000000000000002, 79: 1.0, 80: 1.000000000000001, 81: 0.9999999999999996, 82: 1.0000000000000002, 83: 1.0, 84: 0.9999999999999996, 85: 1.0, 86: 1.0000000000000009, 87: 1.0000000000000013, 88: 1.0000000000000004, 89: 1.0000000000000007, 90: 0.9999999999999997, 91: 1.0000000000000002, 92: 0.9999999999999997, 93: 1.0000000000000004, 94: 0.9999999999999999, 95: 1.0, 96: 1.0, 97: 0.9999999999999994, 98: 1.0000000000000002, 99: 0.9999999999999997, 100: 1.0, 101: 0.9999999999999999, 102: 1.0000000000000004, 103: 1.0000000000000007, 104: 1.0000000000000007, 105: 1.0000000000000009, 106: 1.0000000000000004, 107: 0.9999999999999998, 108: 1.0000000000000002, 109: 0.9999999999999998, 110: 0.9999999999999993, 111: 1.0, 112: 0.9999999999999998, 113: 1.0000000000000007, 114: 0.9999999999999996, 115: 1.0, 116: 1.0000000000000002, 117: 1.0, 118: 1.0000000000000002, 119: 0.9999999999999999, 120: 0.9999999999999998, 121: 0.9999999999999998, 122: 0.9999999999999994, 123: 1.0000000000000009, 124: 1.0000000000000009, 125: 1.0, 126: 1.0000000000000002, 127: 0.9999999999999999, 128: 0.9999999999999999, 129: 0.9999999999999999, 130: 1.0, 131: 1.0, 132: 0.9999999999999999, 133: 1.0000000000000002, 134: 1.0000000000000002, 135: 0.9999999999999994, 136: 1.0, 137: 1.0, 138: 1.0000000000000002, 139: 1.0000000000000007, 140: 1.0, 141: 0.9999999999999993, 142: 0.9999999999999999, 143: 0.9999999999999989, 144: 0.9999999999999993, 145: 1.000000000000001, 146: 1.0000000000000002, 147: 1.0000000000000002, 148: 1.0000000000000004, 149: 0.9999999999999998, 150: 0.9999999999999996, 151: 0.9999999999999993, 152: 1.0000000000000007, 153: 1.0000000000000004, 154: 0.9999999999999999, 155: 1.0000000000000004, 156: 1.0000000000000007, 157: 1.0000000000000002, 158: 1.0000000000000009, 159: 1.000000000000001, 160: 1.0000000000000009, 161: 0.9999999999999998, 162: 1.0000000000000013, 163: 1.0000000000000002, 164: 0.9999999999999989, 165: 1.0000000000000002, 166: 1.000000000000001, 167: 1.0000000000000009, 168: 1.0000000000000004, 169: 0.9999999999999991, 170: 0.9999999999999999, 171: 0.9999999999999992, 172: 0.9999999999999998, 173: 1.0000000000000002, 174: 1.0000000000000004, 175: 0.9999999999999994, 176: 1.000000000000001, 177: 1.0000000000000007, 178: 1.0, 179: 1.0, 180: 1.0000000000000004, 181: 1.0, 182: 0.9999999999999996, 183: 1.0, 184: 0.9999999999999998, 185: 0.9999999999999998, 186: 0.9999999999999996, 187: 0.9999999999999998, 188: 0.9999999999999999, 189: 0.9999999999999988, 190: 0.9999999999999993, 191: 0.9999999999999993, 192: 0.9999999999999998, 193: 0.9999999999999999, 194: 1.0000000000000002, 195: 0.9999999999999997, 196: 1.0000000000000002, 197: 1.0000000000000002, 198: 0.9999999999999996, 199: 1.0000000000000004, 200: 0.9999999999999998, 201: 0.9999999999999991, 202: 1.0000000000000004, 203: 1.0000000000000004, 204: 0.9999999999999997, 205: 1.0, 206: 1.0000000000000002, 207: 0.9999999999999999, 208: 1.0, 209: 1.0000000000000002, 210: 1.0000000000000004, 211: 1.0000000000000002, 212: 1.0000000000000004, 213: 0.9999999999999997, 214: 0.9999999999999993, 215: 1.0000000000000002, 216: 1.0000000000000002, 217: 0.9999999999999998, 218: 0.9999999999999997, 219: 0.9999999999999997, 220: 0.9999999999999998, 221: 1.0, 222: 1.0, 223: 0.9999999999999997, 224: 0.9999999999999999, 225: 1.0000000000000002, 226: 1.0000000000000009, 227: 1.0000000000000002, 228: 0.9999999999999997, 229: 0.9999999999999993, 230: 1.0000000000000004, 231: 1.0000000000000016, 232: 1.0000000000000007, 233: 0.9999999999999999, 234: 1.0000000000000004, 235: 1.0000000000000002, 236: 0.9999999999999998, 237: 0.9999999999999998, 238: 1.0, 239: 0.9999999999999999, 240: 1.0000000000000002, 241: 0.9999999999999994, 242: 1.0, 243: 1.0000000000000002, 244: 0.9999999999999998, 245: 1.0, 246: 1.0000000000000007, 247: 1.0, 248: 1.0000000000000002, 249: 1.0000000000000002, 250: 0.9999999999999994, 251: 1.0, 252: 1.0000000000000002, 253: 1.0, 254: 1.0000000000000004, 255: 0.9999999999999998, 256: 1.0, 257: 1.0000000000000004, 258: 1.0000000000000007, 259: 0.9999999999999998, 260: 0.9999999999999999, 261: 0.9999999999999997, 262: 1.0, 263: 1.0, 264: 1.0000000000000002, 265: 1.0, 266: 0.9999999999999998, 267: 0.9999999999999998, 268: 1.0000000000000007, 269: 1.0000000000000007, 270: 1.0000000000000002, 271: 1.000000000000001, 272: 0.9999999999999996, 273: 0.9999999999999996, 274: 1.0, 275: 1.0000000000000007, 276: 1.0000000000000002, 277: 1.0000000000000002, 278: 1.0, 279: 1.0000000000000002, 280: 1.0000000000000004, 281: 1.0000000000000007, 282: 0.9999999999999993, 283: 0.9999999999999997, 284: 0.9999999999999994, 285: 0.9999999999999997, 286: 0.9999999999999993, 287: 1.0000000000000004, 288: 0.9999999999999997, 289: 0.9999999999999994, 290: 1.0000000000000009, 291: 0.9999999999999998, 292: 1.0000000000000004, 293: 0.9999999999999992, 294: 0.9999999999999998, 295: 1.0, 296: 1.000000000000001, 297: 1.0000000000000004, 298: 0.9999999999999992, 299: 1.0000000000000002, 300: 1.0, 301: 0.9999999999999997, 302: 1.0000000000000004, 303: 0.9999999999999999, 304: 0.9999999999999997, 305: 1.0000000000000004, 306: 0.9999999999999999, 307: 1.0000000000000002, 308: 0.9999999999999989, 309: 0.9999999999999996, 310: 0.9999999999999999, 311: 1.0, 312: 0.9999999999999999, 313: 0.9999999999999996, 314: 1.0, 315: 0.9999999999999994, 316: 1.0, 317: 0.9999999999999997, 318: 1.0, 319: 0.9999999999999998, 320: 1.0000000000000002, 321: 0.9999999999999988, 322: 1.0000000000000013, 323: 1.0000000000000007, 324: 0.9999999999999997, 325: 1.0, 326: 1.0000000000000004, 327: 0.9999999999999997, 328: 1.000000000000001, 329: 1.0000000000000009, 330: 1.0000000000000004, 331: 1.0000000000000002, 332: 0.9999999999999996, 333: 1.0000000000000004, 334: 1.0000000000000004, 335: 0.9999999999999999, 336: 0.9999999999999996, 337: 1.0000000000000002, 338: 0.9999999999999999, 339: 0.9999999999999996, 340: 1.0000000000000002, 341: 1.0000000000000004, 342: 1.0000000000000002, 343: 0.9999999999999998, 344: 0.9999999999999997, 345: 0.9999999999999993, 346: 0.9999999999999998, 347: 0.9999999999999997, 348: 1.0, 349: 1.0, 350: 1.0000000000000009, 351: 1.0000000000000004, 352: 1.0, 353: 0.9999999999999991, 354: 1.0, 355: 1.000000000000001, 356: 1.000000000000001, 357: 0.9999999999999997, 358: 0.9999999999999993, 359: 0.9999999999999992, 360: 0.9999999999999994, 361: 1.0000000000000002, 362: 1.0000000000000013, 363: 1.0000000000000004, 364: 1.000000000000001, 365: 1.0000000000000009, 366: 1.0, 367: 0.9999999999999999, 368: 1.0000000000000007, 369: 1.0000000000000002, 370: 1.0000000000000002, 371: 0.9999999999999988, 372: 1.0000000000000009, 373: 0.9999999999999997, 374: 0.9999999999999994, 375: 0.9999999999999994, 376: 0.9999999999999989, 377: 1.0000000000000002, 378: 1.0000000000000009, 379: 1.0, 380: 1.0, 381: 0.9999999999999991, 382: 0.9999999999999998, 383: 0.9999999999999999, 384: 1.0000000000000007, 385: 1.000000000000001, 386: 0.9999999999999999, 387: 1.0000000000000007, 388: 1.0000000000000007, 389: 0.9999999999999999, 390: 1.0000000000000009, 391: 1.0000000000000002, 392: 1.0000000000000004, 393: 1.0000000000000002, 394: 0.9999999999999994, 395: 1.0000000000000009, 396: 1.0000000000000009, 397: 1.0000000000000002, 398: 0.9999999999999998, 399: 0.9999999999999998, 400: 0.9999999999999998, 401: 1.0000000000000007, 402: 1.0000000000000013, 403: 1.0000000000000009, 404: 1.0000000000000016, 405: 0.9999999999999997, 406: 1.0000000000000002, 407: 1.0000000000000002, 408: 0.9999999999999997, 409: 1.0000000000000002, 410: 1.0000000000000007, 411: 1.0000000000000016, 412: 1.0000000000000004, 413: 0.9999999999999998, 414: 1.0000000000000004, 415: 0.9999999999999997, 416: 1.0000000000000004, 417: 0.9999999999999992, 418: 0.9999999999999997, 419: 1.0000000000000002, 420: 1.0000000000000002, 421: 0.9999999999999999, 422: 0.9999999999999991, 423: 1.0, 424: 1.0000000000000002, 425: 1.0000000000000002, 426: 1.0, 427: 1.0000000000000013, 428: 1.000000000000001, 429: 1.000000000000001, 430: 0.9999999999999992, 431: 1.0000000000000002, 432: 0.9999999999999996, 433: 1.0000000000000004, 434: 1.000000000000001, 435: 1.0000000000000013, 436: 1.0, 437: 1.0, 438: 1.0000000000000004, 439: 1.0000000000000002, 440: 1.0000000000000009, 441: 1.0000000000000007, 442: 0.9999999999999994, 443: 0.999999999999999, 444: 1.0000000000000004, 445: 0.9999999999999997, 446: 0.9999999999999997, 447: 1.0000000000000009, 448: 1.0, 449: 1.0000000000000009, 450: 0.9999999999999993, 451: 0.9999999999999998, 452: 0.9999999999999998, 453: 0.9999999999999994, 454: 1.0, 455: 1.0000000000000009, 456: 1.0000000000000009, 457: 1.0000000000000007, 458: 1.000000000000001, 459: 0.9999999999999997, 460: 0.9999999999999997, 461: 1.0000000000000002, 462: 0.9999999999999999, 463: 0.9999999999999996, 464: 0.9999999999999998, 465: 1.0000000000000004, 466: 1.0, 467: 0.9999999999999992, 468: 0.9999999999999996, 469: 0.9999999999999997, 470: 0.9999999999999999, 471: 0.9999999999999993, 472: 1.0, 473: 0.9999999999999997, 474: 1.0000000000000004, 475: 1.000000000000001, 476: 1.0000000000000004, 477: 1.0000000000000004, 478: 1.0000000000000004, 479: 1.0000000000000018, 480: 1.000000000000001, 481: 0.9999999999999999, 482: 1.0000000000000002, 483: 1.0000000000000016, 484: 1.0000000000000007, 485: 0.9999999999999999, 486: 0.9999999999999996, 487: 0.9999999999999996, 488: 1.0000000000000002, 489: 1.0000000000000002, 490: 1.0000000000000004, 491: 1.0, 492: 0.9999999999999993, 493: 1.000000000000001, 494: 1.0000000000000002, 495: 1.0, 496: 1.0000000000000002, 497: 1.0000000000000004, 498: 1.0000000000000007, 499: 1.0000000000000007, 500: 0.9999999999999996, 501: 1.0000000000000004, 502: 1.0000000000000009, 503: 0.9999999999999999, 504: 1.0000000000000016, 505: 1.0, 506: 0.9999999999999996, 507: 1.0000000000000004, 508: 1.000000000000001, 509: 0.9999999999999998, 510: 1.0, 511: 0.9999999999999999, 512: 1.0000000000000002, 513: 0.9999999999999998, 514: 1.0000000000000007, 515: 1.0000000000000009, 516: 1.000000000000001, 517: 0.9999999999999993, 518: 0.9999999999999999, 519: 0.9999999999999996, 520: 0.9999999999999998, 521: 0.9999999999999999, 522: 1.0, 523: 1.0, 524: 1.0000000000000007, 525: 1.000000000000001, 526: 1.0000000000000004, 527: 1.0000000000000002, 528: 1.0000000000000002, 529: 0.9999999999999996, 530: 1.0000000000000002, 531: 1.0, 532: 0.9999999999999998, 533: 0.9999999999999997, 534: 1.0000000000000004, 535: 1.0000000000000007, 536: 1.0000000000000004, 537: 1.0000000000000009, 538: 1.0, 539: 1.0000000000000007, 540: 1.0000000000000004, 541: 1.0000000000000009, 542: 1.0, 543: 0.9999999999999997, 544: 1.0000000000000002, 545: 0.9999999999999994, 546: 1.0000000000000004, 547: 0.9999999999999997, 548: 0.9999999999999993, 549: 0.9999999999999996, 550: 0.9999999999999996, 551: 0.9999999999999992, 552: 0.9999999999999992, 553: 1.0, 554: 1.0000000000000016, 555: 1.0000000000000002, 556: 1.000000000000001, 557: 0.9999999999999993, 558: 0.9999999999999996, 559: 0.9999999999999998, 560: 1.0000000000000004, 561: 1.0000000000000009, 562: 1.0000000000000016, 563: 1.000000000000001, 564: 1.0000000000000007, 565: 1.000000000000001, 566: 0.9999999999999996, 567: 1.0000000000000022, 568: 1.000000000000002, 569: 0.9999999999999994, 570: 1.000000000000001, 571: 1.0000000000000009, 572: 1.0000000000000004, 573: 0.9999999999999997, 574: 1.0000000000000002, 575: 0.9999999999999998, 576: 0.9999999999999996, 577: 1.0000000000000004, 578: 1.0000000000000007, 579: 0.9999999999999994, 580: 0.9999999999999999, 581: 0.9999999999999992, 582: 0.9999999999999998, 583: 0.9999999999999998, 584: 1.0000000000000002, 585: 1.0000000000000007, 586: 1.0000000000000002, 587: 0.9999999999999993, 588: 0.9999999999999992, 589: 0.9999999999999997, 590: 1.0000000000000013, 591: 1.0000000000000007, 592: 0.9999999999999996, 593: 1.0, 594: 1.0000000000000007, 595: 0.9999999999999991, 596: 0.9999999999999996, 597: 0.9999999999999997, 598: 1.0000000000000004, 599: 1.0, 600: 0.9999999999999997, 601: 1.0, 602: 0.9999999999999992, 603: 1.0000000000000016, 604: 1.0000000000000002, 605: 0.9999999999999999, 606: 1.0000000000000002, 607: 0.9999999999999996, 608: 1.0, 609: 1.0000000000000004, 610: 1.0000000000000007, 611: 1.0, 612: 1.0000000000000007, 613: 1.0000000000000007, 614: 1.0000000000000007, 615: 1.0000000000000009, 616: 0.9999999999999994, 617: 0.9999999999999991, 618: 1.0, 619: 1.0000000000000002, 620: 1.0000000000000004, 621: 1.0000000000000002, 622: 0.9999999999999998, 623: 0.9999999999999997, 624: 0.9999999999999992, 625: 1.0, 626: 0.9999999999999993, 627: 0.9999999999999994, 628: 0.9999999999999999, 629: 1.0000000000000009, 630: 1.0000000000000009, 631: 0.9999999999999994, 632: 0.9999999999999997, 633: 0.9999999999999998, 634: 0.9999999999999994, 635: 1.0000000000000002, 636: 0.9999999999999994, 637: 0.9999999999999993, 638: 1.0, 639: 0.9999999999999999, 640: 1.0, 641: 1.0000000000000004, 642: 0.9999999999999998, 643: 1.0000000000000004, 644: 1.0000000000000002, 645: 1.0000000000000002, 646: 0.9999999999999997, 647: 1.000000000000001, 648: 1.0000000000000002, 649: 0.9999999999999994, 650: 1.0, 651: 0.9999999999999998, 652: 1.0, 653: 1.0000000000000002, 654: 1.000000000000001, 655: 1.0000000000000009, 656: 0.9999999999999991, 657: 0.9999999999999999, 658: 0.9999999999999992, 659: 1.0000000000000004, 660: 0.9999999999999998, 661: 1.0000000000000009, 662: 1.0000000000000009, 663: 1.0000000000000007, 664: 0.9999999999999997, 665: 0.9999999999999996, 666: 0.9999999999999996, 667: 0.999999999999999, 668: 1.0000000000000004, 669: 0.999999999999999, 670: 0.9999999999999992, 671: 1.0000000000000002, 672: 1.0, 673: 0.9999999999999999, 674: 0.9999999999999997, 675: 0.999999999999999, 676: 0.9999999999999997, 677: 1.0, 678: 1.0000000000000002, 679: 1.0000000000000007, 680: 0.9999999999999994, 681: 0.999999999999999, 682: 0.9999999999999993, 683: 1.0000000000000004, 684: 1.0000000000000004, 685: 1.0000000000000013, 686: 0.9999999999999999, 687: 1.0, 688: 1.0000000000000002, 689: 0.9999999999999998, 690: 0.9999999999999993, 691: 1.0000000000000004, 692: 0.9999999999999999, 693: 1.0, 694: 0.9999999999999999, 695: 1.0000000000000002, 696: 1.0000000000000004, 697: 1.0000000000000007, 698: 1.0000000000000009, 699: 1.0000000000000009, 700: 1.0000000000000009, 701: 0.9999999999999996, 702: 1.0000000000000004, 703: 1.0000000000000009, 704: 1.0000000000000013, 705: 1.0000000000000004, 706: 1.0000000000000007, 707: 1.0, 708: 1.0000000000000009, 709: 1.0, 710: 0.9999999999999999, 711: 0.999999999999999, 712: 1.0, 713: 1.0000000000000002, 714: 1.0, 715: 0.9999999999999996, 716: 0.9999999999999994, 717: 1.0000000000000007, 718: 1.0000000000000004, 719: 1.0, 720: 0.9999999999999999, 721: 0.9999999999999993, 722: 1.0000000000000009, 723: 0.9999999999999998, 724: 0.9999999999999998, 725: 0.9999999999999996, 726: 0.9999999999999998, 727: 0.9999999999999997, 728: 1.0, 729: 1.0000000000000002, 730: 1.0000000000000007, 731: 1.0000000000000002, 732: 1.0000000000000007, 733: 1.0000000000000002, 734: 0.9999999999999993, 735: 1.0000000000000004, 736: 1.0000000000000007, 737: 1.0000000000000002, 738: 1.0000000000000004, 739: 0.9999999999999997, 740: 0.9999999999999993, 741: 0.9999999999999998, 742: 0.999999999999999, 743: 1.0, 744: 1.0000000000000002, 745: 1.0, 746: 1.0000000000000004, 747: 1.0000000000000009, 748: 1.0000000000000016, 749: 0.9999999999999992, 750: 1.0000000000000009, 751: 1.0000000000000002}\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "## Calculate euclidean distance among  scenes\n",
    "zero = [0] * 5000\n",
    "dist = []\n",
    "\n",
    "## Calculate for plays\n",
    "for i in range(len(scene_Vect)):\n",
    "    dst = distance.euclidean(zero,scene_Vect[i:i+1])\n",
    "    dist.append(dst)\n",
    "    \n",
    "dist_scene = {}\n",
    "\n",
    "string = \"\"\n",
    "\n",
    "for i in range(len(dist)):\n",
    "    dist_scene[i] = dist[i]\n",
    "print(\"\\n The euclidean distance  of each play are :\\n\")\n",
    "print(dist_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split the training and testing data sets, as well as genre labels\n",
    "seq = list(range(0,752))\n",
    "vect_train, vect_test, readable_train, readable_test, genre_train, genre_test,dist_train,dist_test,seq_train,seq_test = train_test_split(scene_Vect,scene_Readable, scene_genre,dist_scene,seq,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split the sequence numbers\n",
    "\n",
    "# seq_train,seq_test = train_test_split(seq,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest using scene vectorized data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest using scene vectorized data...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 10) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest_vect = forest.fit(vect_train, genre_train)\n",
    "results_vect = forest.predict(vect_test)\n",
    "# print(results)\n",
    "# print(\"the actual labels are\\n\")\n",
    "# print(genre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted results using vectorized features trainig model are\n",
      "\n",
      "[3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0]\n",
      "the actual results are \n",
      "\n",
      "[3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0]\n",
      "Analysis of prediction results using vectorized features trainig model are\n",
      "\n",
      "Homogeneity: 0.582\n",
      "Completeness: 0.570\n",
      "V-measure: 0.576\n",
      "Adjusted Rand-Index: 0.583\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# results = results.map(lambda x: x.strip('[').strip(']'))\n",
    "predict_results_vect = []\n",
    "for j in range(len(results_vect)):\n",
    "    predict_results_vect.insert(-1,float(results_vect[j].strip('[').strip(']')))\n",
    "\n",
    "\n",
    "## Convert actual results to float array for homogeneity comparison\n",
    "# r = genre_test[0].map(lambda x: x.strip('[').strip(']'))\n",
    "r = genre_test\n",
    "r = np.array(r)\n",
    "actual_results = []\n",
    "for i in range(len(r)):\n",
    "    actual_results.insert(-1,float(r[i]))\n",
    "\n",
    "print(\"the predicted results using vectorized features trainig model are\\n\")\n",
    "print(predict_results_vect)\n",
    "print(\"the actual results are \\n\")\n",
    "print(actual_results)\n",
    "# b = [1,2,4,4]\n",
    "print(\"Analysis of prediction results using vectorized features trainig model are\\n\")\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(predict_results_vect, actual_results))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(predict_results_vect, actual_results))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(predict_results_vect, actual_results))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(predict_results_vect, actual_results))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(scene_Vect, predict_results, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest using scene readability feature data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest using scene readability feature data...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest_read = forest.fit(readable_train, genre_train)\n",
    "results_read = forest.predict(readable_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted results using vectorized features trainig model are\n",
      "\n",
      "[3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0]\n",
      "the actual results are \n",
      "\n",
      "[3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0]\n",
      "Analysis of prediction results using vectorized features trainig model are\n",
      "\n",
      "Homogeneity: 0.111\n",
      "Completeness: 0.110\n",
      "V-measure: 0.110\n",
      "Adjusted Rand-Index: 0.113\n"
     ]
    }
   ],
   "source": [
    "# results = results.map(lambda x: x.strip('[').strip(']'))\n",
    "predict_results_read = []\n",
    "for j in range(len(results_read)):\n",
    "    predict_results_read.insert(-1,float(results_read[j].strip('[').strip(']')))\n",
    "\n",
    "\n",
    "## Convert actual results to float array for homogeneity comparison\n",
    "# r = genre_test[0].map(lambda x: x.strip('[').strip(']'))\n",
    "# r = np.array(r)\n",
    "# actual_results = []\n",
    "# for i in range(len(r)):\n",
    "#     actual_results.insert(-1,float(r[i]))\n",
    "\n",
    "print(\"the predicted results using vectorized features trainig model are\\n\")\n",
    "print(predict_results_read)\n",
    "print(\"the actual results are \\n\")\n",
    "print(actual_results)\n",
    "print(\"Analysis of prediction results using vectorized features trainig model are\\n\")\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(predict_results_read, actual_results))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(predict_results_read, actual_results))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(predict_results_read, actual_results))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(predict_results_read, actual_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(68, 0.9999999999999988), (227, 0.9999999999999988), (82, 0.9999999999999989), (74, 0.999999999999999), (160, 0.999999999999999), (171, 0.999999999999999), (225, 0.999999999999999), (265, 0.999999999999999), (266, 0.999999999999999), (197, 0.9999999999999991), (254, 0.9999999999999991), (329, 0.9999999999999991), (336, 0.9999999999999991), (28, 0.9999999999999992), (110, 0.9999999999999992), (135, 0.9999999999999992), (219, 0.9999999999999992), (246, 0.9999999999999992), (367, 0.9999999999999992), (375, 0.9999999999999992), (83, 0.9999999999999993), (186, 0.9999999999999993), (194, 0.9999999999999993), (208, 0.9999999999999993), (214, 0.9999999999999993), (216, 0.9999999999999993), (233, 0.9999999999999993), (261, 0.9999999999999993), (263, 0.9999999999999993), (332, 0.9999999999999993), (340, 0.9999999999999993), (356, 0.9999999999999993), (5, 0.9999999999999994), (7, 0.9999999999999994), (18, 0.9999999999999994), (65, 0.9999999999999994), (72, 0.9999999999999994), (106, 0.9999999999999994), (107, 0.9999999999999994), (127, 0.9999999999999994), (159, 0.9999999999999994), (182, 0.9999999999999994), (238, 0.9999999999999994), (306, 0.9999999999999994), (324, 0.9999999999999994), (343, 0.9999999999999994), (358, 0.9999999999999994), (2, 0.9999999999999996), (48, 0.9999999999999996), (120, 0.9999999999999996), (123, 0.9999999999999996), (134, 0.9999999999999996), (141, 0.9999999999999996), (183, 0.9999999999999996), (199, 0.9999999999999996), (222, 0.9999999999999996), (237, 0.9999999999999996), (239, 0.9999999999999996), (240, 0.9999999999999996), (244, 0.9999999999999996), (256, 0.9999999999999996), (264, 0.9999999999999996), (267, 0.9999999999999996), (270, 0.9999999999999996), (288, 0.9999999999999996), (344, 0.9999999999999996), (371, 0.9999999999999996), (374, 0.9999999999999996), (44, 0.9999999999999997), (46, 0.9999999999999997), (50, 0.9999999999999997), (70, 0.9999999999999997), (76, 0.9999999999999997), (79, 0.9999999999999997), (93, 0.9999999999999997), (95, 0.9999999999999997), (96, 0.9999999999999997), (113, 0.9999999999999997), (114, 0.9999999999999997), (142, 0.9999999999999997), (147, 0.9999999999999997), (157, 0.9999999999999997), (176, 0.9999999999999997), (185, 0.9999999999999997), (189, 0.9999999999999997), (190, 0.9999999999999997), (205, 0.9999999999999997), (226, 0.9999999999999997), (231, 0.9999999999999997), (258, 0.9999999999999997), (305, 0.9999999999999997), (330, 0.9999999999999997), (334, 0.9999999999999997), (341, 0.9999999999999997), (351, 0.9999999999999997), (352, 0.9999999999999997), (362, 0.9999999999999997), (365, 0.9999999999999997), (11, 0.9999999999999998), (20, 0.9999999999999998), (25, 0.9999999999999998), (33, 0.9999999999999998), (36, 0.9999999999999998), (57, 0.9999999999999998), (67, 0.9999999999999998), (75, 0.9999999999999998), (90, 0.9999999999999998), (91, 0.9999999999999998), (109, 0.9999999999999998), (129, 0.9999999999999998), (130, 0.9999999999999998), (131, 0.9999999999999998), (164, 0.9999999999999998), (202, 0.9999999999999998), (251, 0.9999999999999998), (257, 0.9999999999999998), (274, 0.9999999999999998), (282, 0.9999999999999998), (298, 0.9999999999999998), (301, 0.9999999999999998), (307, 0.9999999999999998), (309, 0.9999999999999998), (318, 0.9999999999999998), (346, 0.9999999999999998), (355, 0.9999999999999998), (363, 0.9999999999999998), (368, 0.9999999999999998), (369, 0.9999999999999998), (373, 0.9999999999999998), (15, 0.9999999999999999), (23, 0.9999999999999999), (35, 0.9999999999999999), (54, 0.9999999999999999), (63, 0.9999999999999999), (98, 0.9999999999999999), (133, 0.9999999999999999), (150, 0.9999999999999999), (166, 0.9999999999999999), (170, 0.9999999999999999), (175, 0.9999999999999999), (177, 0.9999999999999999), (191, 0.9999999999999999), (230, 0.9999999999999999), (236, 0.9999999999999999), (249, 0.9999999999999999), (276, 0.9999999999999999), (279, 0.9999999999999999), (291, 0.9999999999999999), (316, 0.9999999999999999), (328, 0.9999999999999999), (335, 0.9999999999999999), (342, 0.9999999999999999), (348, 0.9999999999999999), (361, 0.9999999999999999), (9, 1.0), (12, 1.0), (21, 1.0), (39, 1.0), (45, 1.0), (51, 1.0), (53, 1.0), (69, 1.0), (102, 1.0), (103, 1.0), (112, 1.0), (125, 1.0), (126, 1.0), (138, 1.0), (144, 1.0), (152, 1.0), (154, 1.0), (155, 1.0), (161, 1.0), (163, 1.0), (165, 1.0), (167, 1.0), (179, 1.0), (200, 1.0), (201, 1.0), (209, 1.0), (211, 1.0), (212, 1.0), (224, 1.0), (241, 1.0), (253, 1.0), (271, 1.0), (272, 1.0), (283, 1.0), (294, 1.0), (304, 1.0), (308, 1.0), (320, 1.0), (321, 1.0), (322, 1.0), (323, 1.0), (325, 1.0), (326, 1.0), (327, 1.0), (331, 1.0), (337, 1.0), (338, 1.0), (350, 1.0), (359, 1.0), (364, 1.0), (366, 1.0), (0, 1.0000000000000002), (3, 1.0000000000000002), (6, 1.0000000000000002), (10, 1.0000000000000002), (14, 1.0000000000000002), (16, 1.0000000000000002), (19, 1.0000000000000002), (22, 1.0000000000000002), (24, 1.0000000000000002), (26, 1.0000000000000002), (27, 1.0000000000000002), (30, 1.0000000000000002), (37, 1.0000000000000002), (49, 1.0000000000000002), (55, 1.0000000000000002), (56, 1.0000000000000002), (61, 1.0000000000000002), (62, 1.0000000000000002), (66, 1.0000000000000002), (80, 1.0000000000000002), (85, 1.0000000000000002), (86, 1.0000000000000002), (108, 1.0000000000000002), (124, 1.0000000000000002), (128, 1.0000000000000002), (137, 1.0000000000000002), (145, 1.0000000000000002), (146, 1.0000000000000002), (168, 1.0000000000000002), (169, 1.0000000000000002), (173, 1.0000000000000002), (180, 1.0000000000000002), (181, 1.0000000000000002), (195, 1.0000000000000002), (196, 1.0000000000000002), (198, 1.0000000000000002), (206, 1.0000000000000002), (217, 1.0000000000000002), (221, 1.0000000000000002), (228, 1.0000000000000002), (232, 1.0000000000000002), (234, 1.0000000000000002), (245, 1.0000000000000002), (247, 1.0000000000000002), (260, 1.0000000000000002), (280, 1.0000000000000002), (281, 1.0000000000000002), (292, 1.0000000000000002), (295, 1.0000000000000002), (313, 1.0000000000000002), (333, 1.0000000000000002), (347, 1.0000000000000002), (349, 1.0000000000000002), (353, 1.0000000000000002), (360, 1.0000000000000002), (372, 1.0000000000000002), (4, 1.0000000000000004), (13, 1.0000000000000004), (29, 1.0000000000000004), (32, 1.0000000000000004), (38, 1.0000000000000004), (42, 1.0000000000000004), (43, 1.0000000000000004), (47, 1.0000000000000004), (60, 1.0000000000000004), (64, 1.0000000000000004), (73, 1.0000000000000004), (77, 1.0000000000000004), (78, 1.0000000000000004), (81, 1.0000000000000004), (84, 1.0000000000000004), (89, 1.0000000000000004), (92, 1.0000000000000004), (94, 1.0000000000000004), (100, 1.0000000000000004), (116, 1.0000000000000004), (117, 1.0000000000000004), (121, 1.0000000000000004), (132, 1.0000000000000004), (136, 1.0000000000000004), (143, 1.0000000000000004), (149, 1.0000000000000004), (153, 1.0000000000000004), (156, 1.0000000000000004), (158, 1.0000000000000004), (174, 1.0000000000000004), (184, 1.0000000000000004), (192, 1.0000000000000004), (203, 1.0000000000000004), (218, 1.0000000000000004), (250, 1.0000000000000004), (269, 1.0000000000000004), (278, 1.0000000000000004), (286, 1.0000000000000004), (289, 1.0000000000000004), (293, 1.0000000000000004), (300, 1.0000000000000004), (302, 1.0000000000000004), (310, 1.0000000000000004), (312, 1.0000000000000004), (319, 1.0000000000000004), (1, 1.0000000000000007), (17, 1.0000000000000007), (40, 1.0000000000000007), (88, 1.0000000000000007), (105, 1.0000000000000007), (115, 1.0000000000000007), (118, 1.0000000000000007), (122, 1.0000000000000007), (151, 1.0000000000000007), (188, 1.0000000000000007), (193, 1.0000000000000007), (204, 1.0000000000000007), (210, 1.0000000000000007), (255, 1.0000000000000007), (259, 1.0000000000000007), (262, 1.0000000000000007), (275, 1.0000000000000007), (284, 1.0000000000000007), (285, 1.0000000000000007), (296, 1.0000000000000007), (297, 1.0000000000000007), (345, 1.0000000000000007), (357, 1.0000000000000007), (8, 1.0000000000000009), (41, 1.0000000000000009), (52, 1.0000000000000009), (59, 1.0000000000000009), (97, 1.0000000000000009), (104, 1.0000000000000009), (111, 1.0000000000000009), (139, 1.0000000000000009), (162, 1.0000000000000009), (178, 1.0000000000000009), (215, 1.0000000000000009), (223, 1.0000000000000009), (242, 1.0000000000000009), (268, 1.0000000000000009), (287, 1.0000000000000009), (290, 1.0000000000000009), (299, 1.0000000000000009), (303, 1.0000000000000009), (314, 1.0000000000000009), (315, 1.0000000000000009), (354, 1.0000000000000009), (370, 1.0000000000000009), (58, 1.000000000000001), (71, 1.000000000000001), (87, 1.000000000000001), (119, 1.000000000000001), (148, 1.000000000000001), (172, 1.000000000000001), (187, 1.000000000000001), (207, 1.000000000000001), (213, 1.000000000000001), (235, 1.000000000000001), (248, 1.000000000000001), (252, 1.000000000000001), (273, 1.000000000000001), (277, 1.000000000000001), (317, 1.000000000000001), (339, 1.000000000000001), (140, 1.0000000000000013), (229, 1.0000000000000013), (243, 1.0000000000000013), (311, 1.0000000000000013), (31, 1.0000000000000016), (34, 1.0000000000000016), (99, 1.0000000000000016), (220, 1.0000000000000016), (101, 1.0000000000000022)]\n"
     ]
    }
   ],
   "source": [
    "# Creat a distance of the test files dictionary and then sorted them\n",
    "dist_test_dict = {}\n",
    "\n",
    "for i in range(len(dist_test)):\n",
    "    dist_test_dict[i] = dist_test[i]\n",
    "\n",
    "import operator\n",
    "sorted_dist_test = sorted(dist_test_dict.items(), key=operator.itemgetter(1))\n",
    "print(sorted_dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-f19330ca727b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneib\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         while j+i < len(sorted_dist_test):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_dist_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fill the slide window\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# array to hold the predicted genre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# array to hold the actual genre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Calcualte the average accuracy based on the number of neighbors\n",
    "neib = 5\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "# print(sorted_dist_test[0])\n",
    "for i in range(len(sorted_dist_test)): # Loop through all distance test array\n",
    "    window = [] # A slide window which has the size of neib plus 1\n",
    "    for j in range(neib + 1):\n",
    "#         while j+i < len(sorted_dist_test):\n",
    "        window.append(sorted_dist_test[j+i]) # fill the slide window\n",
    "    result = [] # array to hold the predicted genre\n",
    "    actual = [] # array to hold the actual genre\n",
    "#     print(window)\n",
    "    for (x, y) in window:\n",
    "        result.insert(-1,predict_results_vect[x])\n",
    "        actual.insert(-1,actual_results[x])\n",
    "#         result.append[predict_results_vect[x]]\n",
    "#         actual.append[actual_results[x]]\n",
    "    accuracy.insert(-1,0.582/0.96*metrics.homogeneity_score(actual, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.458071357816\n",
      "[0.60624999999999996, 0.60625000000000007, 0.60625000000000007, 0.29536328809107554, 0.29536328809107554, 0.44479376471979659, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.38153558175907631, 0.43062538770089864, 0.4154822091204618, 0.44479376471979659, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.4154822091204618, 0.4154822091204618, 0.43062538770089864, 0.38153558175907637, 0.38153558175907637, 0.41548220912046185, 0.60624999999999996, 0.60624999999999996, 0.31485051914119272, 0.38153558175907631, 0.43062538770089864, 0.43062538770089864, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.4154822091204618, 0.38153558175907631, 0.31485051914119272, -2.614244673108919e-16, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.2769881394136412, 0.43062538770089864, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.4154822091204618, 0.38153558175907631, 0.38153558175907631, 0.38153558175907631, 0.41548220912046185, 0.44479376471979659, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.44479376471979659, 0.46775593029317936, 0.60625000000000018, 0.60625000000000018, 0.60625000000000018, 0.60624999999999996, 0.46775593029317936, 0.4154822091204618, 0.43062538770089864, 0.46775593029317936, 0.2769881394136412, 0.2769881394136412, 0.38153558175907637, 0.31485051914119272, 0.31485051914119272, 0.38153558175907637, 0.60624999999999996, 0.60624999999999996, 0.44479376471979659, 0.44479376471979659, 0.41548220912046185, 0.44479376471979659, 0.029121269822053191, 0.029121269822053191, 0.20907506347196281, 0.38153558175907637, 0.31485051914119272, 0.34427817651928827, 0.60625000000000007, 0.60625000000000007, 0.60624999999999996, 0.44479376471979659, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.40416666666666673, 0.38618656745551327, 0.40416666666666673, 0.60624999999999996, 0.46775593029317936, 0.43062538770089864, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.3838531176401016, 0.32926186058635876, 0.32926186058635876, 0.35124922459820274, 0.27007275172429052, 0.38153558175907637, 0.38153558175907637, 0.38153558175907637, 0.41548220912046185, 0.30312499999999998, 0.44479376471979659, 0.41548220912046185, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.46775593029317936, 0.43062538770089864, 0.38153558175907637, 0.41548220912046185, 0.049533150604465663, 0.27835842469776717, 0.16612313491102676, 0.32926186058635876, 0.35124922459820274, 0.4154822091204618, 0.44479376471979659, 0.60625000000000007, 0.29536328809107554, 0.30312499999999998, 0.19076779087953821, 0.38153558175907631, 0.31485051914119272, -1.0574355485002426e-16, 0.27007275172429052, 0.19076779087953821, 0.30312499999999998, 0.32926186058635876, 0.32926186058635876, 0.41548220912046185, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.43062538770089864, 0.43062538770089864, 0.46775593029317936, 0.46775593029317936, 0.41548220912046185, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.34427817651928827, 0.19076779087953813, 0.052878695660481055, 0.12188129415939002, 0.052878695660481055, 0.19076779087953813, 0.27698813941364125, 0.44479376471979659, 0.44479376471979659, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.44479376471979659, 0.41548220912046185, 0.32926186058635876, 0.35124922459820274, 0.19076779087953821, 0.22471441824092361, 0.22471441824092361, 0.22471441824092361, 0.22471441824092361, 0.16145623528020325, 0.27698813941364114, 0.41548220912046169, 0.43062538770089864, 0.43062538770089864, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.41548220912046169, 0.41548220912046169, 0.34427817651928827, 0.3838531176401016, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.41548220912046169, 0.41548220912046169, 0.38153558175907631, 0.38153558175907637, 0.20907506347196281, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.31485051914119272, 0.38153558175907631, 0.38153558175907631, 0.13157868201746994, 0.13157868201746994, 0.22374883689730402, 0.43062538770089864, 0.43062538770089864, 0.41548220912046169, 0.43062538770089864, 0.41548220912046169, 0.4154822091204618, 0.43062538770089864, 0.32926186058635876, 0.2769881394136412, 0.17562461229910126, 0.2769881394136412, 0.2769881394136412, 0.46775593029317936, 0.46775593029317936, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.31485051914119272, 0.31485051914119272, 0.38153558175907631, 0.43062538770089864, 0.46775593029317936, 0.27698813941364125, 0.43062538770089864, 0.38153558175907631, 0.38153558175907631, 0.38153558175907631, 0.38153558175907631, 0.60624999999999996, 0.60624999999999996, 0.60625000000000007, 0.29536328809107554, 0.29536328809107554, 0.30312499999999998, 0.19076779087953821, 0.079304960844752317, 0.079304960844752317, 0.079304960844752317, 6.6548336028002987e-17, 6.6548336028002987e-17, 0.11571766842654758, 0.11571766842654758, 0.38153558175907637, 0.38153558175907637, 0.38153558175907637, 0.43062538770089864, 0.19076779087953821, 0.27835842469776717, 0.20907506347196281, 0.38153558175907631, 0.38153558175907631, 0.38153558175907631, 0.38153558175907631, 0.4154822091204618, 0.46775593029317936, 0.43062538770089864, 0.43062538770089864, 0.43062538770089864, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.46775593029317936, 0.4154822091204618, 0.4154822091204618, 0.38153558175907631, 0.27007275172429052, 0.27007275172429052, 0.38153558175907637, 0.43062538770089864, 0.46775593029317936, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996, 0.60624999999999996]\n"
     ]
    }
   ],
   "source": [
    "# x = window[1]\n",
    "# print(x)0.949333333333, 0.90222814746,0.845654325925,0.800576662234,0.775901210531,0.747490140506\n",
    "# 0.725        1\n",
    "# 0.689026061  3\n",
    "# 0.645820983  7\n",
    "# 0.61139545   15\n",
    "# 0.59255096   31\n",
    "# 0.570853601  63\n",
    "\n",
    "# Print the average accuracy\n",
    "print (np.mean(accuracy))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
